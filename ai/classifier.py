"""
AI åˆ†ç±»æœåŠ¡æ¨¡å—
æ‰€æœ‰æ–‡ä»¶éƒ½äº¤ç»™ AI è¯†åˆ«ï¼Œæœ¬åœ°åªåšé¢„å¤„ç†
"""
import json
import re
import time
from pathlib import Path
from typing import Optional
from dataclasses import dataclass

from config import config
from ai.client import AIClient
from ai.parser import MediaInfo, format_size
from ai.prompts import build_prompt, build_context_prompt

# Debug å¼€å…³ - å¼€å‘æ—¶è®¾ä¸º Trueï¼Œå‘å¸ƒæ—¶è®¾ä¸º False
DEBUG_CLASSIFIER = True

# æ ‡å‡†ç•ªå·æ ¼å¼æ­£åˆ™ï¼š
# 1. å­—æ¯å¼€å¤´ + çŸ­æ¨ª + æ•°å­—ï¼ˆå¦‚ ADN-256ï¼‰
# 2. å­—æ¯å¼€å¤´ + æ•°å­—ï¼ˆæ— çŸ­æ¨ªï¼Œå¦‚ gachip318ï¼‰
# 3. FC2-PPV æ ¼å¼
RE_VALID_CODE = re.compile(
    r'^[A-Za-z]{2,6}-\d{3,7}$|'    # ABC-123 æ ¼å¼
    r'^[A-Za-z]{2,8}\d{3,5}$|'      # ABC123 æ ¼å¼ï¼ˆæ— çŸ­æ¨ªï¼‰
    r'^FC2-?PPV-?\d{5,7}$',         # FC2-PPV æ ¼å¼
    re.IGNORECASE
)


@dataclass
class ClassifyOptions:
    """åˆ†ç±»é€‰é¡¹"""
    # ç”¨æˆ·è‡ªå®šä¹‰æç¤º
    hint: str = ""
    # æ¯æ‰¹å¤„ç†æ•°é‡
    batch_size: int = 30
    # Debug æ¨¡å¼
    debug: bool = False
    # æ˜¯å¦è·³è¿‡é¢„å‘Šç‰‡/æ ·ç‰‡
    skip_trailers: bool = True


class MediaClassifier:
    """åª’ä½“åˆ†ç±»æœåŠ¡"""
    
    def __init__(self, ai_client: AIClient = None):
        self.ai = ai_client or AIClient()
    
    def classify_batch(self, media_list: list[MediaInfo], 
                       options: ClassifyOptions = None) -> dict:
        """
        æ‰¹é‡åˆ†ç±»åª’ä½“æ–‡ä»¶
        
        Args:
            media_list: å¾…åˆ†ç±»çš„åª’ä½“åˆ—è¡¨
            options: åˆ†ç±»é€‰é¡¹
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        options = options or ClassifyOptions()
        
        # æ„å»ºæ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        file_info = []
        for i, info in enumerate(media_list, 1):
            file_info.append(f"{i}. {info.filename} ({format_size(info.size_bytes)})")
        
        # ä½¿ç”¨ prompts æ¨¡å—æ„å»ºæ¶ˆæ¯
        messages = build_prompt(file_info, options.hint, options.skip_trailers)
        
        # ä»é…ç½®è¯»å– temperatureï¼ˆä½¿ç”¨ä½æ¸©åº¦å’Œå›ºå®š seed æé«˜ç»“æœä¸€è‡´æ€§ï¼‰
        temperature = config.get("ai", "temperature", default=0.1)
        response = self.ai.chat(messages, temperature=temperature, seed=42)
        
        if not response:
            # è¿”å›é”™è¯¯ä¿¡æ¯ä¾›å¤–éƒ¨ä½¿ç”¨
            return {"error": self.ai.last_error or "API è¯·æ±‚å¤±è´¥"}
        
        # è§£æå“åº”
        try:
            result = self._parse_response(response)
            return result
        except Exception as e:
            print(f"è§£æ AI å“åº”å¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response[:500]}...")
            return {"error": f"è§£æå“åº”å¤±è´¥: {e}"}
    
    def classify_with_context(self, media_list: list[MediaInfo], 
                              options: ClassifyOptions = None) -> dict:
        """
        äºŒæ¬¡æ£€æµ‹ï¼šå¸¦è·¯å¾„ä¸Šä¸‹æ–‡çš„åˆ†ç±»
        
        Args:
            media_list: éœ€è¦äºŒæ¬¡æ£€æµ‹çš„æ–‡ä»¶åˆ—è¡¨
            options: åˆ†ç±»é€‰é¡¹ï¼ˆåŒ…å«ç”¨æˆ·è‡ªå®šä¹‰ hintï¼‰
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        options = options or ClassifyOptions()
        
        # æ„å»ºå¸¦æ–‡ä»¶å¤¹ä¿¡æ¯å’Œé¦–æ¬¡è¯†åˆ«ç±»å‹çš„æ–‡ä»¶åˆ—è¡¨
        file_info = []
        for i, info in enumerate(media_list, 1):
            # æå–ä¸Šçº§æ–‡ä»¶å¤¹å
            parent_folder = Path(info.filepath).parent.name
            # åŒ…å«é¦–æ¬¡è¯†åˆ«çš„ç±»å‹ï¼Œå¸®åŠ© AI ä¿æŒä¸€è‡´æ€§
            first_pass_type = info.media_type if info.media_type and info.media_type != "unknown" else "å¾…å®š"
            file_info.append(
                f"{i}. {info.filename} ({format_size(info.size_bytes)}) [æ–‡ä»¶å¤¹: {parent_folder}] [é¦–æ¬¡åˆ¤æ–­: {first_pass_type}]"
            )
        
        if DEBUG_CLASSIFIER:
            print(f"  ğŸ“ äºŒæ¬¡æ£€æµ‹è¯·æ±‚: {len(file_info)} ä¸ªæ–‡ä»¶")
        
        # ä½¿ç”¨äºŒæ¬¡æ£€æµ‹ä¸“ç”¨ Prompt
        messages = build_context_prompt(file_info, options.hint)
        
        # è°ƒç”¨ AIï¼ˆä½¿ç”¨è¾ƒä½æ¸©åº¦æé«˜ä¸€è‡´æ€§ï¼‰
        response = self.ai.chat(messages, temperature=0.2)
        
        if not response:
            return {"error": self.ai.last_error or "API è¯·æ±‚å¤±è´¥"}
        
        if DEBUG_CLASSIFIER:
            # æ˜¾ç¤ºå“åº”çš„å‰200å­—ç¬¦
            preview = response[:200].replace('\n', ' ')
            print(f"  ğŸ“¨ äºŒæ¬¡æ£€æµ‹å“åº”é¢„è§ˆ: {preview}...")
        
        # è§£æå“åº”
        try:
            result = self._parse_response(response)
            if DEBUG_CLASSIFIER:
                results_list = result.get("results", []) or result.get("files", [])
                print(f"  ğŸ“Š è§£æç»“æœ: {len(results_list)} ä¸ªé¡¹ç›®")
            return result
        except Exception as e:
            print(f"è§£æäºŒæ¬¡æ£€æµ‹å“åº”å¤±è´¥: {e}")
            if DEBUG_CLASSIFIER:
                print(f"  åŸå§‹å“åº”: {response[:500]}")
            return {"error": f"è§£æå“åº”å¤±è´¥: {e}"}
    
    def _parse_response(self, response: str) -> dict:
        """è§£æ AI å“åº”"""
        response = response.strip()
        
        # å¦‚æœå“åº”è¢« markdown ä»£ç å—åŒ…è£¹
        if "```" in response:
            lines = response.split('\n')
            json_lines = []
            in_json = False
            for line in lines:
                if line.strip().startswith("```json") or line.strip() == "```":
                    in_json = not in_json if line.strip() == "```" else True
                    continue
                if in_json:
                    json_lines.append(line)
            response = '\n'.join(json_lines)
        
        parsed = json.loads(response)
        
        # å¦‚æœ AI ç›´æ¥è¿”å›äº†åˆ—è¡¨è€Œä¸æ˜¯å­—å…¸ï¼ŒåŒ…è£…æˆæ ‡å‡†æ ¼å¼
        if isinstance(parsed, list):
            return {"results": parsed}
        
        return parsed
    
    def apply_results(self, media_list: list[MediaInfo], 
                      ai_result: dict) -> list[MediaInfo]:
        """
        å°† AI ç»“æœåº”ç”¨åˆ°åª’ä½“åˆ—è¡¨
        
        Args:
            media_list: åŸå§‹åª’ä½“åˆ—è¡¨
            ai_result: AI è¿”å›çš„ç»“æœ
            
        Returns:
            æ›´æ–°åçš„åª’ä½“åˆ—è¡¨
        """
        if not ai_result:
            return media_list
        
        # å…¼å®¹ AI è¿”å› "results" æˆ– "files" ä¸¤ç§æ ¼å¼
        results = ai_result.get("results", []) or ai_result.get("files", [])
        
        # è®°å½•å·²å¤„ç†çš„ç´¢å¼•
        processed_indices = set()
        
        for item in results:
            idx = item.get("index", 0)
            if 1 <= idx <= len(media_list):
                processed_indices.add(idx)
                info = media_list[idx - 1]
                # æ–°æ ¼å¼ä½¿ç”¨å•ä¸€ title å­—æ®µ
                info.title = item.get("title", "") or item.get("title_cn", "") or item.get("title_en", "")
                info.title_en = item.get("title_en", "")  # å…¼å®¹æ—§æ ¼å¼
                info.year = item.get("year")
                info.media_type = self._normalize_type(item.get("type", "å…¶ä»–"))
                info.resolution = item.get("resolution", "")
                info.source = item.get("source", "")
                info.season = item.get("season")
                info.episode = item.get("episode")
                # NSFW ç•ªå· - éªŒè¯æ ¼å¼æ˜¯å¦æ­£ç¡®
                raw_code = item.get("code", "") or ""
                if raw_code and RE_VALID_CODE.match(raw_code):
                    info.code = raw_code.upper()
                else:
                    info.code = ""  # æ— æ•ˆæ ¼å¼ä¸è®¾ç½®
                # æ–°å¢å­—æ®µ
                info.skip = item.get("skip", False)
                info.needs_context = item.get("needs_context", False)
                
                # å¦‚æœéœ€è¦äºŒæ¬¡æ£€æµ‹ï¼Œåˆ™ä¸åº”è¯¥è·³è¿‡
                if info.needs_context:
                    info.skip = False
                
                info.parsed = True
                info.needs_ai = False
                
                # Debug è¾“å‡º
                if DEBUG_CLASSIFIER:
                    if info.skip:
                        print(f"  ğŸš« SKIP: {info.filename}")
                    elif info.needs_context:
                        print(f"  ğŸ” éœ€è¦äºŒæ¬¡æ£€æµ‹: {info.filename}")
                    if info.code:
                        print(f"  ğŸ“Œ ç•ªå·: {info.code} â† {info.filename}")
                    elif raw_code and not info.code:
                        print(f"  ğŸ“ æœªæ£€æµ‹åˆ°æœ‰æ•ˆç•ªå·: {info.filename}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶æœªè¢« AI è¿”å›ï¼ˆå¯èƒ½è¢«å†…å®¹å®¡æŸ¥è¿‡æ»¤ï¼‰
        # è¿™äº›æ–‡ä»¶è‡ªåŠ¨æ ‡è®°ä¸ºéœ€è¦äºŒæ¬¡æ£€æµ‹
        for i, info in enumerate(media_list, 1):
            if i not in processed_indices and not info.parsed:
                info.needs_context = True
                info.parsed = True  # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œé¿å…é‡å¤
                if DEBUG_CLASSIFIER:
                    print(f"  âš ï¸ AIæœªè¿”å›ç»“æœï¼Œè‡ªåŠ¨è¿›å…¥äºŒæ¬¡æ£€æµ‹: {info.filename}")
        
        return media_list
    
    def _normalize_type(self, type_str: str) -> str:
        """
        æ ‡å‡†åŒ–ç±»å‹å­—ç¬¦ä¸²
        
        ç°åœ¨ç›´æ¥è¿”å› AI ç»™çš„ç±»å‹ï¼ˆè½¬ä¸ºå°å†™ï¼‰ï¼Œä¸å†ç¡¬ç¼–ç æ˜ å°„ã€‚
        è¿™æ ·å¯ä»¥æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰çš„ä»»æ„æ ‡ç­¾ã€‚
        """
        if not type_str:
            return "other"
        
        # ç›´æ¥è¿”å›å°å†™å¤„ç†åçš„ç±»å‹
        # è¿™æ ·ç”¨æˆ·è‡ªå®šä¹‰çš„æ ‡ç­¾å¦‚ "nsfe av" å¯ä»¥æ­£ç¡®ä¿ç•™
        return type_str.lower().strip()


class BatchClassifier:
    """æ‰¹é‡åˆ†ç±»å¤„ç†å™¨"""
    
    def __init__(self, classifier: MediaClassifier = None):
        self.classifier = classifier or MediaClassifier()
    
    def process(self, media_list: list[MediaInfo],
                options: ClassifyOptions = None,
                progress_callback=None,
                cancel_check=None) -> list[MediaInfo]:
        """
        å¤„ç†æ•´ä¸ªåª’ä½“åˆ—è¡¨ï¼ˆå…¨éƒ¨äº¤ç»™ AIï¼‰
        
        Args:
            media_list: åª’ä½“åˆ—è¡¨
            options: åˆ†ç±»é€‰é¡¹
            progress_callback: è¿›åº¦å›è°ƒ (current, total, message)
            cancel_check: å–æ¶ˆæ£€æŸ¥å‡½æ•°ï¼Œè¿”å› True è¡¨ç¤ºåº”å–æ¶ˆ
            
        Returns:
            å¤„ç†åçš„åˆ—è¡¨
        """
        options = options or ClassifyOptions()
        
        # å…¨éƒ¨æ–‡ä»¶éƒ½éœ€è¦ AI å¤„ç†
        total = len(media_list)
        if total == 0:
            return media_list
        
        processed = 0
        failed_files = 0  # è¿½è¸ªå›  API é”™è¯¯æœªèƒ½å¤„ç†çš„æ–‡ä»¶æ•°
        error_messages = []  # æ”¶é›†é”™è¯¯ä¿¡æ¯
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, total, options.batch_size):
            # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
            if cancel_check and cancel_check():
                if progress_callback:
                    progress_callback(processed, total, "â¹ï¸ å·²å–æ¶ˆ")
                return media_list
            
            batch = media_list[i:i + options.batch_size]
            batch_end = min(i + options.batch_size, total)
            
            if progress_callback:
                progress_callback(
                    processed, total,
                    f"AI è¯†åˆ«ä¸­: {i+1}-{batch_end} / {total}"
                )
            
            # è°ƒç”¨ AI
            try:
                result = self.classifier.classify_batch(batch, options)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ API é”™è¯¯
                if "error" in result:
                    error_msg = result["error"]
                    if progress_callback:
                        progress_callback(processed, total, f"  âŒ æ‰¹æ¬¡ {i+1}-{batch_end} å¤±è´¥: {error_msg}")
                    print(f"æ‰¹æ¬¡ {i+1}-{batch_end} API é”™è¯¯: {error_msg}")
                    failed_files += len(batch)
                    if error_msg not in error_messages:
                        error_messages.append(error_msg)
                else:
                    # åº”ç”¨ç»“æœ
                    self.classifier.apply_results(batch, result)
            except Exception as e:
                if progress_callback:
                    progress_callback(processed, total, f"  âš ï¸ æ‰¹æ¬¡ {i+1}-{batch_end} å‡ºé”™: {e}")
                failed_files += len(batch)
                if str(e) not in error_messages:
                    error_messages.append(str(e))
            
            processed += len(batch)
            
            # TPM é™é€Ÿï¼šæ‰¹æ¬¡é—´å»¶è¿Ÿ
            batch_delay = config.get("ai", "batch_delay_ms", default=500)
            if batch_delay > 0 and i + options.batch_size < total:
                time.sleep(batch_delay / 1000.0)

        
        # ====================
        # äºŒæ¬¡æ£€æµ‹æµç¨‹
        # ====================
        needs_context = [m for m in media_list if getattr(m, 'needs_context', False)]
        
        if needs_context:
            if progress_callback:
                progress_callback(total, total, f"äºŒæ¬¡æ£€æµ‹ä¸­: {len(needs_context)} ä¸ªæ–‡ä»¶éœ€è¦ä¸Šä¸‹æ–‡...")
            
            if DEBUG_CLASSIFIER:
                print(f"\nğŸ”„ å¼€å§‹äºŒæ¬¡æ£€æµ‹: {len(needs_context)} ä¸ªæ–‡ä»¶")
            
            # åˆ†æ‰¹è¿›è¡ŒäºŒæ¬¡æ£€æµ‹
            for i in range(0, len(needs_context), options.batch_size):
                # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
                if cancel_check and cancel_check():
                    if progress_callback:
                        progress_callback(total, total, "â¹ï¸ å·²å–æ¶ˆ")
                    return media_list
                
                batch = needs_context[i:i + options.batch_size]
                batch_end = min(i + options.batch_size, len(needs_context))
                
                if DEBUG_CLASSIFIER:
                    print(f"  ğŸ“¦ äºŒæ¬¡æ£€æµ‹æ‰¹æ¬¡: {i+1}-{batch_end} / {len(needs_context)}")
                
                if progress_callback:
                    progress_callback(
                        total, total,
                        f"äºŒæ¬¡æ£€æµ‹: {i+1}-{batch_end} / {len(needs_context)}"
                    )

                
                try:
                    result = self.classifier.classify_with_context(batch, options)
                    
                    if "error" in result:
                        if progress_callback:
                            progress_callback(total, total, f"  âŒ äºŒæ¬¡æ£€æµ‹å¤±è´¥: {result['error']}")
                        if DEBUG_CLASSIFIER:
                            print(f"  âŒ äºŒæ¬¡æ£€æµ‹å¤±è´¥: {result['error']}")
                    else:
                        # åº”ç”¨ç»“æœï¼ˆä¼šè¦†ç›–ä¹‹å‰çš„ needs_context çŠ¶æ€ï¼‰
                        results_count = len(result.get("results", []) or result.get("files", []))
                        if DEBUG_CLASSIFIER:
                            print(f"  âœ… äºŒæ¬¡æ£€æµ‹å®Œæˆ: æ”¶åˆ° {results_count} ä¸ªç»“æœ")
                        
                        self.classifier.apply_results(batch, result)
                        # æ¸…é™¤ needs_context æ ‡è®°
                        for item in batch:
                            item.needs_context = False
                except Exception as e:
                    if progress_callback:
                        progress_callback(total, total, f"  âš ï¸ äºŒæ¬¡æ£€æµ‹å‡ºé”™: {e}")
                    if DEBUG_CLASSIFIER:
                        print(f"  âš ï¸ äºŒæ¬¡æ£€æµ‹å‡ºé”™: {e}")
                    failed_files += len(batch)
                    if str(e) not in error_messages:
                        error_messages.append(str(e))
        
        # è¾“å‡ºå®Œæˆä¿¡æ¯å’Œé”™è¯¯æ±‡æ€»
        if progress_callback:
            progress_callback(total, total, "AI è¯†åˆ«å®Œæˆ")
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºæ±‡æ€»
            if failed_files > 0:
                progress_callback(total, total, f"âš ï¸ ç½‘ç»œ/API é—®é¢˜å¯¼è‡´ {failed_files} ä¸ªæ–‡ä»¶æœªèƒ½è¯†åˆ«")
                for err in error_messages[:3]:  # æœ€å¤šæ˜¾ç¤º3æ¡é”™è¯¯
                    progress_callback(total, total, f"   åŸå› : {err}")
        
        return media_list
